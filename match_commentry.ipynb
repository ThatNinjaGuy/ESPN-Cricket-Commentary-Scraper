{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new virtual environment\n",
    "# python3 -m venv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: selenium in ./venv/lib/python3.12/site-packages (4.21.0)\n",
      "Requirement already satisfied: webdriver-manager in ./venv/lib/python3.12/site-packages (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: trio~=0.17 in ./venv/lib/python3.12/site-packages (from selenium) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./venv/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in ./venv/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from webdriver-manager) (24.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in ./venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in ./venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in ./venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in ./venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./venv/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in ./venv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./venv/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 1/18: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/united-states-of-america-vs-canada-1st-match-group-a-1415701/ball-by-ball-commentary\n",
      "Fetching URL: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/united-states-of-america-vs-canada-1st-match-group-a-1415701/ball-by-ball-commentary\n",
      "Error processing URLhttps://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/united-states-of-america-vs-canada-1st-match-group-a-1415701/ball-by-ball-commentary with error Message: Can not connect to the Service /Users/deadshot/.wdm/drivers/chromedriver/mac64/125.0.6422.141/chromedriver-mac-arm64/chromedriver\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service process refused to terminate gracefully with SIGTERM, escalating to SIGKILL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deadshot/Desktop/Code/Match Commentry Scraper/venv/lib/python3.12/site-packages/selenium/webdriver/common/service.py\", line 172, in _terminate_process\n",
      "    self.process.wait(60)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 1264, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 2045, in _wait\n",
      "    raise TimeoutExpired(self.args, timeout)\n",
      "subprocess.TimeoutExpired: Command '['/Users/deadshot/.wdm/drivers/chromedriver/mac64/125.0.6422.141/chromedriver-mac-arm64/chromedriver', '--port=57492']' timed out after 60 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 2/18: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/west-indies-vs-papua-new-guinea-2nd-match-group-c-1415702/ball-by-ball-commentary\n",
      "Fetching URL: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/west-indies-vs-papua-new-guinea-2nd-match-group-c-1415702/ball-by-ball-commentary\n",
      "Error processing URLhttps://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/west-indies-vs-papua-new-guinea-2nd-match-group-c-1415702/ball-by-ball-commentary with error Message: Can not connect to the Service /Users/deadshot/.wdm/drivers/chromedriver/mac64/125.0.6422.141/chromedriver-mac-arm64/chromedriver\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service process refused to terminate gracefully with SIGTERM, escalating to SIGKILL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deadshot/Desktop/Code/Match Commentry Scraper/venv/lib/python3.12/site-packages/selenium/webdriver/common/service.py\", line 172, in _terminate_process\n",
      "    self.process.wait(60)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 1264, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 2045, in _wait\n",
      "    raise TimeoutExpired(self.args, timeout)\n",
      "subprocess.TimeoutExpired: Command '['/Users/deadshot/.wdm/drivers/chromedriver/mac64/125.0.6422.141/chromedriver-mac-arm64/chromedriver', '--port=57675']' timed out after 60 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 3/18: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/namibia-vs-oman-3rd-match-group-b-1415703/ball-by-ball-commentary\n",
      "Fetching URL: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/namibia-vs-oman-3rd-match-group-b-1415703/ball-by-ball-commentary\n",
      "Error processing URLhttps://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/namibia-vs-oman-3rd-match-group-b-1415703/ball-by-ball-commentary with error Message: Can not connect to the Service /Users/deadshot/.wdm/drivers/chromedriver/mac64/125.0.6422.141/chromedriver-mac-arm64/chromedriver\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service process refused to terminate gracefully with SIGTERM, escalating to SIGKILL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deadshot/Desktop/Code/Match Commentry Scraper/venv/lib/python3.12/site-packages/selenium/webdriver/common/service.py\", line 172, in _terminate_process\n",
      "    self.process.wait(60)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 1264, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py\", line 2045, in _wait\n",
      "    raise TimeoutExpired(self.args, timeout)\n",
      "subprocess.TimeoutExpired: Command '['/Users/deadshot/.wdm/drivers/chromedriver/mac64/125.0.6422.141/chromedriver-mac-arm64/chromedriver', '--port=57896']' timed out after 60 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL 4/18: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/south-africa-vs-sri-lanka-4th-match-group-d-1415704/ball-by-ball-commentary\n",
      "Fetching URL: https://www.espncricinfo.com/series/icc-men-s-t20-world-cup-2024-1411166/south-africa-vs-sri-lanka-4th-match-group-d-1415704/ball-by-ball-commentary\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 199\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProcessing URL \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(urls)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     soups \u001b[39m=\u001b[39m extract_html_content(idx, url)\n\u001b[1;32m    200\u001b[0m     \u001b[39mfor\u001b[39;00m idx, soup \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(soups):\n\u001b[1;32m    201\u001b[0m         data \u001b[39m=\u001b[39m extract_commentary_data(idx, soup, url)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mextract_html_content\u001b[0;34m(idx, url)\u001b[0m\n\u001b[1;32m      8\u001b[0m options\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--no-sandbox\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m options\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--disable-dev-shm-usage\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(service\u001b[39m=\u001b[39;49mService(ChromeDriverManager()\u001b[39m.\u001b[39;49minstall()), options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m     12\u001b[0m driver\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m     14\u001b[0m soups \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/Code/Match Commentry Scraper/venv/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[39m=\u001b[39m service \u001b[39mif\u001b[39;00m service \u001b[39melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[39m=\u001b[39m options \u001b[39mif\u001b[39;00m options \u001b[39melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     46\u001b[0m     browser_name\u001b[39m=\u001b[39;49mDesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m\"\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     47\u001b[0m     vendor_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     48\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m     49\u001b[0m     service\u001b[39m=\u001b[39;49mservice,\n\u001b[1;32m     50\u001b[0m     keep_alive\u001b[39m=\u001b[39;49mkeep_alive,\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Code/Match Commentry Scraper/venv/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py:55\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     52\u001b[0m     options\u001b[39m.\u001b[39mbrowser_version \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m finder\u001b[39m.\u001b[39mget_driver_path()\n\u001b[0;32m---> 55\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m     57\u001b[0m executor \u001b[39m=\u001b[39m ChromiumRemoteConnection(\n\u001b[1;32m     58\u001b[0m     remote_server_addr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mservice_url,\n\u001b[1;32m     59\u001b[0m     browser_name\u001b[39m=\u001b[39mbrowser_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     ignore_proxy\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Code/Match Commentry Scraper/venv/lib/python3.12/site-packages/selenium/webdriver/common/service.py:106\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m# sleep increasing: 0.01, 0.06, 0.11, 0.16, 0.21, 0.26, 0.31, 0.36, 0.41, 0.46, 0.5\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m sleep(\u001b[39mmin\u001b[39;49m(\u001b[39m0.01\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m0.05\u001b[39;49m \u001b[39m*\u001b[39;49m count, \u001b[39m0.5\u001b[39;49m))\n\u001b[1;32m    107\u001b[0m count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m count \u001b[39m==\u001b[39m \u001b[39m70\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def extract_html_content(idx, url):\n",
    "    print(f'Fetching URL: {url}')\n",
    "    \n",
    "    # Set up the Selenium WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Run in headless mode for faster execution\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    soups = []\n",
    "    dropdown_xpath = '//div[contains(@class, \"ds-flex ds-items-center ds-border-ui-stroke ds-h-6 ds-px-4 ds-border ds-bg-ui-fill ds-rounded-full ds-w-full ds-min-w-max ds-cursor-pointer\")]'\n",
    "    dropdown_items_xpath = '//ul[contains(@class, \"ds-flex ds-flex-col ds-text-typo-mid2 ds-justify-center ds-overflow-ellipsis ds-overflow-y-auto ds-w-full ds-grid ds-grid-cols-1 ds-items-center ds-gap-x-2 ds-max-h-96 ds-overflow-y-auto\")]/li/div'\n",
    "    \n",
    "    # Find and click the dropdown to expand it\n",
    "    dropdown = driver.find_element(By.XPATH, dropdown_xpath)\n",
    "    driver.execute_script(\"arguments[0].click();\", dropdown)\n",
    "    time.sleep(2)  # Wait for the dropdown to open\n",
    "    \n",
    "    # Find all items in the dropdown\n",
    "    dropdown_items = driver.find_elements(By.XPATH, dropdown_items_xpath)\n",
    "    \n",
    "    for item_idx, item in enumerate(dropdown_items):\n",
    "        try:\n",
    "            print(f'Clicking on item {item_idx}: {item.text.strip()}')  # Print the item text for debugging\n",
    "            driver.execute_script(\"arguments[0].click();\", item)\n",
    "            time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "            # Scroll until no more content is loaded\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            scroll_attempts = 0\n",
    "            scroll_successful = 0\n",
    "            total_scroll_attempts = 0\n",
    "            screenshot_count = 0\n",
    "\n",
    "            while True:\n",
    "                # Scroll down using large scrolls\n",
    "                driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "                time.sleep(2)  # Wait for new content to load\n",
    "\n",
    "                # Scroll up and down to load content in the viewport\n",
    "                for i in range(150):\n",
    "                    total_scroll_attempts += 1\n",
    "                    key = Keys.ARROW_UP\n",
    "                    driver.find_element(By.TAG_NAME, 'body').send_keys(key)\n",
    "                    if i % 8 == 0:\n",
    "                        time.sleep(0.3)  # Wait for new content to load\n",
    "\n",
    "                # Fine-tune scrolling to ensure all content is loaded\n",
    "                for i in range(100):\n",
    "                    total_scroll_attempts += 1\n",
    "                    key = Keys.ARROW_DOWN\n",
    "                    driver.find_element(By.TAG_NAME, 'body').send_keys(key)\n",
    "                    if i % 8 == 0:\n",
    "                        time.sleep(0.3)  # Wait for new content to load\n",
    "\n",
    "                # Capture a screenshot after scrolling\n",
    "                # screenshot_path = f'screenshot_{idx}_{item_idx}_{screenshot_count}.png'\n",
    "                # driver.save_screenshot(screenshot_path)\n",
    "                # print(f'Screenshot saved at {screenshot_path}')\n",
    "                screenshot_count += 1\n",
    "\n",
    "                # Check if we reached the end of the page\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    scroll_attempts += 1\n",
    "                    if scroll_attempts >= 2:\n",
    "                        break\n",
    "                else:\n",
    "                    scroll_attempts = 0\n",
    "                    scroll_successful += 1\n",
    "\n",
    "                last_height = new_height\n",
    "\n",
    "                # Print progress\n",
    "                print(f'Scroll Attempts: {total_scroll_attempts}, Scrolls Successful: {scroll_successful}', end='\\r')\n",
    "\n",
    "            # Get the page source and parse the HTML content with BeautifulSoup\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            soups.append(soup)\n",
    "\n",
    "            # Click the dropdown again to select the next item\n",
    "            dropdown = driver.find_element(By.XPATH, dropdown_xpath)\n",
    "            driver.execute_script(\"arguments[0].click();\", dropdown)\n",
    "            time.sleep(2)  # Wait for the dropdown to open\n",
    "            dropdown_items = driver.find_elements(By.XPATH, dropdown_items_xpath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing the click of dropdown for dropdown item index:{item_idx}\")\n",
    "\n",
    "    driver.quit()\n",
    "    print(f'\\nSuccessfully fetched and parsed URL: {url}')\n",
    "    return soups\n",
    "\n",
    "\n",
    "def extract_match_details(url):\n",
    "    # Updated regular expression to capture the match details\n",
    "    pattern = re.compile(\n",
    "        r\"https://www\\.espncricinfo\\.com/series/icc-men-s-t20-world-cup-2024-1411166/([a-zA-Z-]+)-vs-([a-zA-Z-]+)-(\\d+)[a-z]{2}-match-group-([a-z])-([0-9]+)/ball-by-ball-commentary\"\n",
    "    )\n",
    "    match = pattern.match(url)\n",
    "    if match:\n",
    "        details = match.groups()\n",
    "        print(f\"Match details found: {details}\")  # Debug print\n",
    "\n",
    "        team_1 = details[0].replace('-', ' ').title()\n",
    "        team_2 = details[1].replace('-', ' ').title()\n",
    "        match_number = details[2]\n",
    "        group_id = details[3].upper()\n",
    "        match_id = details[4]\n",
    "\n",
    "        return team_1, team_2, match_number, match_id, group_id\n",
    "    else:\n",
    "        print(\"No match found.\")  # Debug print\n",
    "        return None\n",
    "\n",
    "def extract_commentary_data(idx, soup, url):\n",
    "    print('Extracting commentary data')\n",
    "    data = []\n",
    "    # Extract match details\n",
    "    team_1, team_2, match_number, match_id, group_id = extract_match_details(url)\n",
    "    # Find all commentary blocks\n",
    "    commentary_blocks = soup.find_all('div', class_='ds-text-tight-m ds-font-regular ds-flex ds-px-3 ds-py-2 lg:ds-px-4 lg:ds-py-[10px] ds-items-start ds-select-none lg:ds-select-auto')\n",
    "    print(f'Found {len(commentary_blocks)} commentary blocks')\n",
    "\n",
    "    for index, block in enumerate(commentary_blocks, start=1):\n",
    "        try:\n",
    "            # Extract the over\n",
    "            over_elem = block.find('span', class_='ds-text-tight-s ds-font-regular ds-mb-1 lg:ds-mb-0 lg:ds-mr-3 ds-block ds-text-center ds-text-typo-mid1')\n",
    "            over = over_elem.text.strip() if over_elem else None\n",
    "            \n",
    "            # Extract the runs\n",
    "            runs_block = block.find('div', class_='lg:ds-flex lg:ds-items-center lg:ds-px-2')\n",
    "            runs = None\n",
    "            if runs_block:\n",
    "                runs = runs_block.find('div', class_='ds-flex ds-items-center ds-justify-center ds-rounded ds-overflow-hidden ds-bg-raw-green-d2 ds-text-raw-white') or \\\n",
    "                runs_block.find('div', class_='ds-text-tight-m ds-font-bold ds-flex ds-items-center ds-justify-center ds-text-center ds-w-10 ds-h-10 ds-text-raw-white') or \\\n",
    "                runs_block.find('div', class_='ds-flex ds-items-center ds-justify-center ds-rounded ds-overflow-hidden ds-bg-ui-fill-default-translucent ds-text-typo') or \\\n",
    "                runs_block.find('div', class_='ds-flex ds-items-center ds-justify-center ds-rounded ds-overflow-hidden ds-bg-raw-red ds-text-raw-white') or \\\n",
    "                runs_block.find('div', class_='ds-flex ds-items-center ds-justify-center ds-rounded ds-overflow-hidden ds-bg-ui-fill-default-translucent ds-text-typo') or \\\n",
    "                runs_block.find('div', class_='ds-flex ds-items-center ds-justify-center ds-rounded ds-overflow-hidden ds-bg-raw-purple ds-text-raw-white')\n",
    "                runs = runs.find('span').text.strip() if runs else None\n",
    "            \n",
    "            # Extract the main message\n",
    "            main_message_elem = block.find('div', class_='ds-leading-none ds-mb-0.5')\n",
    "            main_message = main_message_elem.find('span').text.strip() if main_message_elem else None\n",
    "            \n",
    "            # Extract the complete commentary\n",
    "            complete_commentary_elem = block.find('div', class_='first-letter:ds-capitalize').find('p', class_='ci-html-content')\n",
    "            complete_commentary = complete_commentary_elem.text.strip() if complete_commentary_elem else None\n",
    "            \n",
    "            # Append the extracted data to the list\n",
    "            data.append({\n",
    "                'Match Id': match_id,\n",
    "                'Match Number': match_number,\n",
    "                'Group Number': group_id,\n",
    "                'Team A': team_1,\n",
    "                'Team B': team_2,\n",
    "                'Innings': idx+1,\n",
    "                'Over': over,\n",
    "                'Runs': runs,\n",
    "                'Main Message': main_message,\n",
    "                'Complete Commentary': complete_commentary\n",
    "            })\n",
    "\n",
    "            # Print progress for commentary processing\n",
    "            print(f'Processing progress for commentary: {index}/{len(commentary_blocks)}', end='\\r')\n",
    "        except Exception as e:\n",
    "            print(f'Skipping block {block} due to error: {e}')\n",
    "    \n",
    "    print('\\nCompleted extracting commentary data')\n",
    "    return data\n",
    "\n",
    "def get_processed_data(data, file_appender=''):\n",
    "    print('Processing data into DataFrame')\n",
    "    columns = ['Match Id', 'Match Number', 'Group Number', 'Team A', 'Team B', 'Innings', 'Over', 'Runs', 'Main Message', 'Complete Commentary']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    file_name = f'commentary_results_{file_appender}.csv'\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f'Data saved to {file_name}')\n",
    "    return df\n",
    "\n",
    "def get_urls_to_scrape(csv_file='urls_to_scrape.csv'):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Extract the URLs column into a list\n",
    "    urls = df['Urls'].tolist()\n",
    "    return urls\n",
    "\n",
    "# Main execution\n",
    "combined_data = []\n",
    "urls = get_urls_to_scrape('urls_to_scrape.csv')\n",
    "for idx, url in enumerate(urls):\n",
    "    print(f'Processing URL {idx + 1}/{len(urls)}: {url}')\n",
    "    try:\n",
    "        soups = extract_html_content(idx, url)\n",
    "        for idx, soup in enumerate(soups):\n",
    "            data = extract_commentary_data(idx, soup, url)\n",
    "            combined_data.extend(data)\n",
    "            # get_processed_data(data, idx)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing URL{url} with error {e}')\n",
    "    time.sleep(5)\n",
    "\n",
    "df = get_processed_data(combined_data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
